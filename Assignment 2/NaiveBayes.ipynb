{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizedInput(inputFileName,tokenize=False):\n",
    "    cleaned_list=[]\n",
    "    with open(inputFileName) as f:\n",
    "        docs = f.readlines()\n",
    "\n",
    "    for doc in docs:\n",
    "        raw=None\n",
    "        if(tokenize==True):\n",
    "            raw = tokenizer.tokenize(doc)\n",
    "        else:\n",
    "            raw=doc\n",
    "        cleaned_list.append(raw)\n",
    "    \n",
    "    return cleaned_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train=tokenizedInput('Dataset/Clean1/train_text.txt',tokenize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(x_train))\n",
    "# print(len(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    def __init__(self,x,y,laplace_smoother=1):\n",
    "        self.x=list(x)\n",
    "        self.y=list(y)\n",
    "        self.laplace_smoother=laplace_smoother\n",
    "        self.distinct_x=0\n",
    "        self.distinct_y=0\n",
    "        self.instances=len(y)\n",
    "        self.x_dict={}\n",
    "        self.vocabulary={}\n",
    "        self.y_dict={}\n",
    "        self.revMapy={}\n",
    "        self.wordsInClass=[]\n",
    "        self.instancesInClass=[]\n",
    "    \n",
    "    def calculateParameters(self):\n",
    "#         classes=np.unique(self.npy)\n",
    "        counter=0\n",
    "        for i in range(self.instances):\n",
    "            feature_vector=self.x[i]\n",
    "            feature_class=self.y[i]\n",
    "            mapped_class=counter\n",
    "            \n",
    "            if(feature_class in self.y_dict):\n",
    "                mapped_class=self.y_dict[feature_class]\n",
    "            else:\n",
    "                self.revMapy[counter]=feature_class\n",
    "                self.y_dict[feature_class]=counter\n",
    "                self.wordsInClass.append(0)\n",
    "                self.instancesInClass.append(0)\n",
    "                counter+=1\n",
    "            \n",
    "            self.instancesInClass[mapped_class]+=1\n",
    "            \n",
    "            for words in feature_vector:\n",
    "                if(words in self.vocabulary):\n",
    "                    pass\n",
    "                else:\n",
    "                    self.vocabulary[words]=1\n",
    "                \n",
    "                key=(words,mapped_class)\n",
    "                self.wordsInClass[mapped_class]+=1\n",
    "                \n",
    "                if(key in self.x_dict):\n",
    "                    self.x_dict[key]+=1\n",
    "                else:\n",
    "                    self.x_dict[key]=1\n",
    "            \n",
    "        self.distinct_x=len(self.vocabulary)\n",
    "        self.distinct_y=len(self.y_dict)\n",
    "#         self.printParameters()\n",
    "    \n",
    "    def getLogPrior(self,label):\n",
    "        return math.log(float(self.instancesInClass[label])/self.instances)\n",
    "    \n",
    "    def getLogProb(self,attribute,label):\n",
    "        \n",
    "        occurences=0\n",
    "        key=(attribute,label)\n",
    "        \n",
    "        if key in self.x_dict:\n",
    "            occurences=self.x_dict[key]\n",
    "        \n",
    "        occurences+=self.laplace_smoother\n",
    "        \n",
    "        total_occurences_in_class=self.wordsInClass[label]\n",
    "        total_occurences_in_class+=self.distinct_x*self.laplace_smoother\n",
    "        \n",
    "        return math.log(float(occurences)/total_occurences_in_class)\n",
    "        \n",
    "    def getClass(self,x):\n",
    "        max_log_prob=-1e9\n",
    "        label=-1\n",
    "        \n",
    "        for i in range(self.distinct_y):\n",
    "            log_prob_x_given_y=0\n",
    "            \n",
    "            for attributes in x:\n",
    "                log_prob_x_given_y+=self.getLogProb(attributes,i)\n",
    "            \n",
    "            log_prob_x=log_prob_x_given_y+self.getLogPrior(i)\n",
    "            \n",
    "            if(log_prob_x>max_log_prob):\n",
    "                max_log_prob=log_prob_x\n",
    "                label=self.revMapy[i]\n",
    "            \n",
    "        return label\n",
    "    \n",
    "    def ConfusionMatrix(self,y,predy):\n",
    "#         confusion=[[0]*self.distinct_y]*self.distinct_y\n",
    "        confusion = [ [0]*self.distinct_y for _ in range(self.distinct_y) ]\n",
    "        \n",
    "        tests=len(y)\n",
    "        \n",
    "        for i in range(tests):\n",
    "            confusion[self.y_dict[predy[i]]][self.y_dict[y[i]]]+=1\n",
    "        \n",
    "        for i in range(self.distinct_y):\n",
    "            for j in range(self.distinct_y):\n",
    "#                 print((i,j),end=' ')                                \n",
    "                print(\"%5d\"%(confusion[i][j]),end=' ')\n",
    "            print()\n",
    "        \n",
    "        \n",
    "    def getAccuracy(self,x,y,printConfusionMatrix=False):\n",
    "        total_tests=len(y)\n",
    "        passed_tests=0\n",
    "        prediction_list=[]\n",
    "        \n",
    "        for i in range(total_tests):\n",
    "            xi=x[i]\n",
    "            yi=y[i]\n",
    "            \n",
    "#             if y[i] in self.y_dict:\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 continue\n",
    "            pred_yi=self.getClass(xi)\n",
    "            prediction_list.append(pred_yi)\n",
    "            if(pred_yi==yi):\n",
    "                passed_tests+=1\n",
    "        \n",
    "        if(printConfusionMatrix==True):\n",
    "            self.ConfusionMatrix(y,pred_yi)\n",
    "                \n",
    "        return [prediction_list,(float(passed_tests))/total_tests]\n",
    "    \n",
    "    def getAccuracyRandomPredict(self,x,y):\n",
    "        \n",
    "        average_over=10\n",
    "        total_accuracy=0\n",
    "        \n",
    "        for i in range(average_over):\n",
    "            \n",
    "            total_tests=len(y)\n",
    "            passed_tests=0\n",
    "\n",
    "            for i in range(total_tests):\n",
    "                yi=y[i]\n",
    "\n",
    "                pred_yi=random.randint(0,self.distinct_y-1)\n",
    "                pred_yi=self.revMapy[pred_yi]\n",
    "\n",
    "                if(pred_yi==yi):\n",
    "                    passed_tests+=1\n",
    "\n",
    "            total_accuracy+=(float(passed_tests))/total_tests\n",
    "        \n",
    "        return total_accuracy/average_over\n",
    "    \n",
    "    def getAccuracyMajorityPredictor(self,x,y):\n",
    "        max_occ=-1\n",
    "        majority_class=-1\n",
    "        total_tests=len(y)\n",
    "        passed_tests=0        \n",
    "        \n",
    "        for i in range(self.distinct_y):\n",
    "            if(max_occ<self.instancesInClass[i]):\n",
    "                max_occ=self.instancesInClass[i]\n",
    "                majority_class=i\n",
    "        \n",
    "        if(majority_class==-1):\n",
    "            return 0\n",
    "        \n",
    "        majority_class=self.revMapy[majority_class]\n",
    "        \n",
    "        for yi in y:\n",
    "            if(yi==majority_class):\n",
    "                passed_tests+=1\n",
    "                \n",
    "        return (float(passed_tests))/total_tests       \n",
    "\n",
    "    def printParameters(self):\n",
    "        print(\"Vocabulary Size:\",self.distinct_x)\n",
    "        print(\"Classes:\",self.distinct_y)\n",
    "        print(\"X_Y's:\",len(self.x_dict))\n",
    "        \n",
    "        print(\"Mapped Classes:\", self.y_dict)\n",
    "        \n",
    "        print(\"Instances In Mapped class:\",end='')\n",
    "        \n",
    "        for counts in self.instancesInClass:\n",
    "            print(counts,end=' ')\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"Words In Mapped class:\",end='')\n",
    "        \n",
    "        for counts in self.wordsInClass:\n",
    "            print(counts,end=' ')\n",
    "        \n",
    "        print(\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=tokenizedInput('Dataset/imdb/imdb_train_text.txt',tokenize=True)\n",
    "y_train=tokenizedInput('Dataset/imdb/imdb_train_labels.txt',tokenize=False)\n",
    "y_train=list(map(int,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayesClassifier=NaiveBayes(x=x_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayesClassifier.calculateParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6056873\n"
     ]
    }
   ],
   "source": [
    "print (sum(NaiveBayesClassifier.wordsInClass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (NaiveBayesClassifier.getAccuracy(x_train,y_train))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=tokenizedInput('Dataset/imdb/imdb_test_text.txt',tokenize=True)\n",
    "y_test=tokenizedInput('Dataset/imdb/imdb_test_labels.txt',tokenize=False)\n",
    "y_test=list(map(int,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38408\n"
     ]
    }
   ],
   "source": [
    "[a,b]=(NaiveBayesClassifier.getAccuracy(x_test,y_test,printConfusionMatrix=False))\n",
    "print (b)\n",
    "# print(NaiveBayesClassifier.ConfusionMatrix(a,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (NaiveBayesClassifier.getAccuracyRandomPredict(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (NaiveBayesClassifier.getAccuracyMajorityPredictor(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67984\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2291  1484  1149  1094   125   136   102   238 \n",
      "  896   537   467   427    96   120    88   183 \n",
      "  384   215   204   150    87    77    86   155 \n",
      "  154    98    86    66    13     5     7    24 \n",
      "   59    38    33    38   139   156   100   272 \n",
      "  194   156   133    98   335   370   286   666 \n",
      "   11     5     8     4    27    52    37    52 \n",
      "  743   476   416   386  1598  1780  1578  3510 \n"
     ]
    }
   ],
   "source": [
    "NaiveBayesClassifier.ConfusionMatrix(y_test,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 7, 2: 6, 3: 4, 4: 5, 7: 2, 8: 1, 9: 3, 10: 0}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NaiveBayesClassifier.y_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
