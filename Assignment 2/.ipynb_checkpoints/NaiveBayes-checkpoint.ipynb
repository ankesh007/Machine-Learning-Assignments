{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizedInput(inputFileName,tokenize=False):\n",
    "    cleaned_list=[]\n",
    "    with open(inputFileName) as f:\n",
    "        docs = f.readlines()\n",
    "\n",
    "    for doc in docs:\n",
    "        raw=None\n",
    "        if(tokenize==True):\n",
    "            raw = tokenizer.tokenize(doc)\n",
    "        else:\n",
    "            raw=doc\n",
    "        cleaned_list.append(raw)\n",
    "    \n",
    "    return cleaned_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train=tokenizedInput('Dataset/Clean1/train_text.txt',tokenize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(x_train))\n",
    "# print(len(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    def __init__(self,x,y,laplace_smoother=1):\n",
    "        self.x=list(x)\n",
    "        self.y=list(y)\n",
    "        self.laplace_smoother=laplace_smoother\n",
    "        self.distinct_x=0\n",
    "        self.distinct_y=0\n",
    "        self.instances=len(y)\n",
    "        self.x_dict={}\n",
    "        self.vocabulary={}\n",
    "        self.y_dict={}\n",
    "        self.revMapy={}\n",
    "        self.wordsInClass=[]\n",
    "        self.instancesInClass=[]\n",
    "    \n",
    "    def calculateParameters(self):\n",
    "#         classes=np.unique(self.npy)\n",
    "        counter=0\n",
    "        for i in range(self.instances):\n",
    "            feature_vector=self.x[i]\n",
    "            feature_class=self.y[i]\n",
    "            mapped_class=counter\n",
    "            \n",
    "            if(feature_class in self.y_dict):\n",
    "                mapped_class=self.y_dict[feature_class]\n",
    "            else:\n",
    "                self.revMapy[counter]=feature_class\n",
    "                self.y_dict[feature_class]=counter\n",
    "                self.wordsInClass.append(0)\n",
    "                self.instancesInClass.append(0)\n",
    "                counter+=1\n",
    "            \n",
    "            self.instancesInClass[mapped_class]+=1\n",
    "            \n",
    "            for words in feature_vector:\n",
    "                if(words in self.vocabulary):\n",
    "                    pass\n",
    "                else:\n",
    "                    self.vocabulary[words]=1\n",
    "                \n",
    "                key=(words,mapped_class)\n",
    "                self.wordsInClass[mapped_class]+=1\n",
    "                \n",
    "                if(key in self.x_dict):\n",
    "                    self.x_dict[key]+=1\n",
    "                else:\n",
    "                    self.x_dict[key]=1\n",
    "            \n",
    "        self.distinct_x=len(self.vocabulary)\n",
    "        self.distinct_y=len(self.y_dict)\n",
    "#         self.printParameters()\n",
    "    \n",
    "    def getLogPrior(self,label):\n",
    "        return math.log(float(self.instancesInClass[label])/self.instances)\n",
    "    \n",
    "    def getLogProb(self,attribute,label):\n",
    "        \n",
    "        occurences=0\n",
    "        key=(attribute,label)\n",
    "        \n",
    "        if key in self.x_dict:\n",
    "            occurences=self.x_dict[key]\n",
    "        \n",
    "        occurences+=self.laplace_smoother\n",
    "        \n",
    "        total_occurences_in_class=self.wordsInClass[label]\n",
    "        total_occurences_in_class+=self.distinct_x*self.laplace_smoother\n",
    "        \n",
    "        return math.log(float(occurences)/total_occurences_in_class)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def getClass(self,x):\n",
    "        max_log_prob=-1e9\n",
    "        label=-1\n",
    "        \n",
    "        for i in range(self.distinct_y):\n",
    "            log_prob_x_given_y=0\n",
    "            \n",
    "            for attributes in x:\n",
    "                log_prob_x_given_y+=self.getLogProb(attributes,i)\n",
    "            \n",
    "            log_prob_x=log_prob_x_given_y+self.getLogPrior(i)\n",
    "            \n",
    "            if(log_prob_x>max_log_prob):\n",
    "                max_log_prob=log_prob_x\n",
    "                label=self.revMapy[i]\n",
    "            \n",
    "        return label\n",
    "        \n",
    "        \n",
    "        \n",
    "    def getAccuracy(self,x,y):\n",
    "        total_tests=len(y)\n",
    "        passed_tests=0\n",
    "        \n",
    "        for i in range(total_tests):\n",
    "            xi=x[i]\n",
    "            yi=y[i]\n",
    "            \n",
    "#             if y[i] in self.y_dict:\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 continue\n",
    "            pred_yi=self.getClass(xi)\n",
    "            if(pred_yi==yi):\n",
    "                passed_tests+=1\n",
    "                \n",
    "        return (float(passed_tests))/total_tests\n",
    "            \n",
    "    def printParameters(self):\n",
    "        print(\"Vocabulary Size:\",self.distinct_x)\n",
    "        print(\"Classes:\",self.distinct_y)\n",
    "        print(\"X_Y's:\",len(self.x_dict))\n",
    "        \n",
    "        print(\"Mapped Classes:\", self.y_dict)\n",
    "        \n",
    "        print(\"Instances In Mapped class:\",end='')\n",
    "        \n",
    "        for counts in self.instancesInClass:\n",
    "            print(counts,end=' ')\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"Words In Mapped class:\",end='')\n",
    "        \n",
    "        for counts in self.wordsInClass:\n",
    "            print(counts,end=' ')\n",
    "        \n",
    "        print(\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=tokenizedInput('Dataset/Clean1/train_text.txt',tokenize=True)\n",
    "y_train=tokenizedInput('Dataset/Clean1/imdb_train_labels.txt',tokenize=False)\n",
    "y_train=list(map(int,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayesClassifier=NaiveBayes(x=x_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayesClassifier.calculateParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5956618\n"
     ]
    }
   ],
   "source": [
    "print (sum(NaiveBayesClassifier.wordsInClass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68476\n"
     ]
    }
   ],
   "source": [
    "print (NaiveBayesClassifier.getAccuracy(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=tokenizedInput('Dataset/Clean1/test_text.txt',tokenize=True)\n",
    "y_test=tokenizedInput('Dataset/Clean1/imdb_test_labels.txt',tokenize=False)\n",
    "y_test=list(map(int,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38468\n"
     ]
    }
   ],
   "source": [
    "print (NaiveBayesClassifier.getAccuracy(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
