{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpd=pd.read_csv(\"Dataset/mnist/train.csv\",header=None,sep=',')\n",
    "testpd=pd.read_csv(\"Dataset/mnist/test.csv\",header=None,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    \n",
    "    def __init__(self,x,y,normalize_x=True):\n",
    "        self.x=np.copy(x).astype(float)\n",
    "        self.y=np.copy(y)\n",
    "        [instances,dimensions]=x.shape\n",
    "        self.dimensions=dimensions\n",
    "        self.instances=instances\n",
    "        self.normalize_param=np.ones((1,dimensions))\n",
    "        self.normalize_x=normalize_x\n",
    "        label=np.unique(y).shape[0]\n",
    "        self.label=label\n",
    "        self.weight=np.zeros((self.label,self.label,dimensions))\n",
    "        self.bias=np.zeros((self.label,self.label))\n",
    "        self.epoch=np.zeros((self.label,self.label))\n",
    "        self.train_steps=np.zeros((self.label,self.label))\n",
    "\n",
    "        if(normalize_x==True):\n",
    "            self.normalize_param=self.getNormParam()\n",
    "            self.x=self.normalize(self.x)\n",
    "        \n",
    "    def getNormParam(self):\n",
    "        max_arr=np.amax(self.x,axis=0)\n",
    "        bool_0=(max_arr==0)\n",
    "        max_arr+=bool_0.astype(int)\n",
    "        return max_arr[np.newaxis,:]\n",
    "    \n",
    "    def normalize(self,x):\n",
    "        return (x/self.normalize_param)\n",
    "    \n",
    "    def resetParam(self,i,j):\n",
    "        self.weight[i,j,:]*=0\n",
    "        self.bias[i,j]=0\n",
    "        self.epoch[i,j]=0\n",
    "        self.train_steps[i,j]=0\n",
    "        return\n",
    "    \n",
    "    def evaluate(self,x,y,weight,bias):\n",
    "        return (np.matmul(x,weight)+bias)*y\n",
    "    \n",
    "    def getLoss(self,x,y,lamda,C,weight,bias):\n",
    "        loss=np.matmul(np.transpose(weight),weight)*lamda\n",
    "        evaluate=1-self.evaluate(x=x,y=y,weight=weight,bias=bias)\n",
    "        mask=(evaluate>0).astype(int)\n",
    "        evaluate*=mask\n",
    "        loss+=C*np.sum(evaluate)\n",
    "        return loss\n",
    "    \n",
    "    def getWeight(self,i,j):\n",
    "        return self.weight[i,j,:][:,np.newaxis]\n",
    "    \n",
    "    def train1Classier(self,weight,bias,train_steps,epoch,x=None,y=None,lamda=1,C=1,max_steps=5000,batch_mode=True,batch_size=100,epsilon=0.0001,log_every=1000):\n",
    "\n",
    "        if(x is None):\n",
    "            x=self.x\n",
    "        if(y is None):\n",
    "            y=self.y\n",
    "            \n",
    "        xy=-(x*y)\n",
    "        [instances,dim]=x.shape\n",
    "        [instances,ydim]=y.shape\n",
    "        \n",
    "        if(batch_mode==False):\n",
    "            batch_size=instances\n",
    "        \n",
    "        prev_loss=self.getLoss(x=x,y=y,lamda=lamda,C=C,weight=weight,bias=bias)\n",
    "            \n",
    "        Trained=False    \n",
    "        cur_steps=0\n",
    "        while(Trained==False and cur_steps<max_steps):\n",
    "            cur_instance=0\n",
    "            epoch+=1\n",
    "            \n",
    "            while(cur_instance<instances and cur_steps<max_steps):\n",
    "                train_steps+=1\n",
    "                cur_steps+=1\n",
    "                eta=1.0/(lamda*cur_steps)\n",
    "#                 print(eta)\n",
    "                up_lim=min(instances,cur_instance+batch_size)\n",
    "                batch_x=x[cur_instance:up_lim,0:dim]\n",
    "                batch_y=y[cur_instance:up_lim,0:ydim]\n",
    "                batch_xy=xy[cur_instance:up_lim,0:dim]\n",
    "                examples=up_lim-cur_instance\n",
    "                cur_instance=up_lim\n",
    "                evaluate=self.evaluate(batch_x,batch_y,weight,bias)\n",
    "                mask=((1-evaluate)>0).astype(int)\n",
    "                weight=(1-eta*lamda)*weight - (eta*C*(np.sum(batch_xy*mask,axis=0)[:,np.newaxis]))/examples\n",
    "                bias=bias+((np.sum(mask*batch_y))*C*eta)/examples\n",
    "                \n",
    "                if(train_steps%log_every==0):\n",
    "                    print(train_steps)\n",
    "#                     print(\"Batch Loss at Steps=\",train_steps,\" is \",self.getLoss(x,y,lamda,C,weight,bias))\n",
    "            \n",
    "            cur_loss=self.getLoss(x,y,lamda,C,weight,bias)\n",
    "            if(abs(cur_loss-prev_loss)<epsilon):\n",
    "                prev_loss=cur_loss\n",
    "                Trained=True\n",
    "                \n",
    "            prev_loss=cur_loss\n",
    "        \n",
    "        print(prev_loss)\n",
    "\n",
    "        return (weight,bias,epoch,train_steps)\n",
    "    \n",
    "    def trainIJclassifier(self,i,j,reset=False):\n",
    "        \n",
    "        if(reset==True):\n",
    "            self.resetParam(i,j)\n",
    "        \n",
    "        print(\"********************************************************\")\n",
    "        print(i,\" \",j,\" \",\"Classifier\")\n",
    "        \n",
    "        aux_arr=(self.y==i).astype(int)+(self.y==j).astype(int)\n",
    "\n",
    "        newx=self.x[aux_arr[:,0]>0]\n",
    "        newy=self.y[aux_arr[:,0]>0]\n",
    "        newy=np.copy(newy)\n",
    "        newy=((newy==i).astype(int))-((newy==j).astype(int))\n",
    "\n",
    "        (weight,bias,epoch,train_steps)=self.train1Classier(weight=self.getWeight(i,j),\n",
    "                                          bias=self.bias[i,j],\n",
    "                                          x=newx,\n",
    "                                          y=newy,\n",
    "                                          train_steps=self.train_steps[i,j],\n",
    "                                          epoch=self.epoch[i,j])\n",
    "        \n",
    "        self.weight[i,j,:]=weight[:,0]\n",
    "        self.bias[i,j]=bias\n",
    "        self.epoch[i,j]=epoch\n",
    "        self.train_steps[i,j]=train_steps\n",
    "        \n",
    "    def train(self):\n",
    "        for i in range(self.label):\n",
    "            for j in range(i+1,self.label,1):\n",
    "                self.trainIJclassifier(i,j)\n",
    "\n",
    "    def getClass(self,x,i,j):\n",
    "        weight=self.getWeight(i,j)\n",
    "        \n",
    "        if(np.matmul(weight.T,x)+self.bias[i,j]>0):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "                \n",
    "    def predictInstance(self,x):\n",
    "        \n",
    "        count=[]\n",
    "        for i in range(self.label):\n",
    "            count.append(0)\n",
    "            \n",
    "        for i in range(self.label):\n",
    "            for j in range(i+1,self.label,1):\n",
    "                aux_class=self.getClass(x,i,j)\n",
    "                if(aux_class==1):\n",
    "                    count[i]+=1\n",
    "                else:\n",
    "                    count[j]+=1\n",
    "        \n",
    "        coun=0\n",
    "        lab=-1\n",
    "        \n",
    "        for i in range(self.label):\n",
    "\n",
    "            if(coun<=count[i]):\n",
    "                coun=count[i]\n",
    "                lab=i\n",
    "        return lab\n",
    "    \n",
    "    def predict(self,x):\n",
    "        predictions=[]\n",
    "        \n",
    "        instances=x.shape[0]\n",
    "        \n",
    "        for i in range(instances):\n",
    "            predictions.append(self.predictInstance(x[i][::,np.newaxis]))\n",
    "        \n",
    "        return np.asarray(predictions)[:,np.newaxis]\n",
    "            \n",
    "    def getAccuracy(self,x,y):\n",
    "        predictions=self.predict(x.astype(float))\n",
    "        \n",
    "        mask_correct=np.sum((predictions==y).astype(int))\n",
    "        instances=y.shape[0]\n",
    "        \n",
    "        return float(mask_correct)/instances\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDataframe(dataframe):\n",
    "    values=dataframe.values\n",
    "    [instances,dim]=values.shape\n",
    "    x=values[:,0:dim-1]\n",
    "    y=values[:,dim-1:dim]\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train)=parseDataframe(trainpd)\n",
    "(x_test,y_test)=parseDataframe(testpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 784)\n",
      "(20000, 1)\n",
      "(10000, 784)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_instance=SVM(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM_instance.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8772"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_instance.getAccuracy(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def getClass(x,i,j):\n",
    "#         weight=SVM_instance.getWeight(i,j) \n",
    "#         if(np.matmul(weight.T,x)+SVM_instance.bias[i,j]>0):\n",
    "#             return 1\n",
    "#         else:\n",
    "#             return 0\n",
    "                \n",
    "#     def predictInstance(x):\n",
    "        \n",
    "#         count=[]\n",
    "#         for i in range(SVM_instance.label):\n",
    "#             count.append(0)\n",
    "            \n",
    "#         for i in range(SVM_instance.label):\n",
    "#             for j in range(i+1,SVM_instance.label,1):\n",
    "#                 aux_class=getClass(x,i,j)\n",
    "#                 if(aux_class==1):\n",
    "#                     count[i]+=1\n",
    "#                 else:\n",
    "#                     count[j]+=1\n",
    "        \n",
    "#         coun=0\n",
    "#         lab=-1\n",
    "        \n",
    "#         for i in range(SVM_instance.label):\n",
    "#             print(count[i],end=' ')\n",
    "#             if(coun<count[i]):\n",
    "#                 coun=count[i]\n",
    "#                 lab=i\n",
    "#         print()\n",
    "#         return lab\n",
    "    \n",
    "#     def predict(x):\n",
    "        \n",
    "#         predictions=[]\n",
    "        \n",
    "#         instances=x.shape[0]\n",
    "        \n",
    "#         for i in range(instances):\n",
    "#             y=predictInstance(x[i][::,np.newaxis])\n",
    "#             predictions.append(y)\n",
    "        \n",
    "#         return np.asarray(predictions)[:,np.newaxis]\n",
    "    \n",
    "#     def getAccuracy(x,y):\n",
    "#         predictions=predict(x.astype(float)[0:10,:])\n",
    "        \n",
    "#         mask_correct=np.sum((predictions==y[0:10,:]).astype(int))\n",
    "#         instances=y.shape[0]\n",
    "#         print(mask_correct)\n",
    "        \n",
    "#         return float(mask_correct)/instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=SVM_instance.weight\n",
    "bias=SVM_instance.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_instance.weight=weights\n",
    "SVM_bias=bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
